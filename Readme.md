# ğŸ“„ Document Classification and Extraction System

![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-active-brightgreen)
![Made With](https://img.shields.io/badge/Made%20with-ğŸ’™%20Transformers%20%26%20DSPy-blue)

A powerful end-to-end pipeline for **document classification and extraction**, designed for processing **resumes, emails, scientific publications**, and more.

This project combines **state-of-the-art transformer models**, **small language models (SLMs)**, and **OCR**, powered by a robust API-first architecture with a web-based frontend.
[kaggle dataset for training classifier](https://www.kaggle.com/datasets/ritvik1909/document-classification-dataset)
---

## ğŸ“ Repository Structure
```bash
â”œâ”€â”€ frontend      # Web application for uploading and processing documents
â”œâ”€â”€ api           # Backend API for inference, classification, and extraction
â”œâ”€â”€ experiments   # Jupyter notebooks for model training, testing, experiments
â”œâ”€â”€ ocr           # OCR utilities for scanned and image-based documents
```
___
## ğŸš€ Core Components

### ğŸ“‘ Document Classifier

- âœ… Fine-tuned **BERT-based uncased model** hosted on Hugging Face.
- ğŸ”— [Check My finetuned model on Hugging Face](https://huggingface.co/visithck/Bert-Based-Docu-classify). This is opensource and available on my huggingface repo.
- ğŸ“Š Trained on the [Kaggle Document Classification Dataset](https://www.kaggle.com/datasets/ritvik1909/document-classification-dataset).
- ğŸ§  Built using Hugging Face **Transformers**.
- âš™ï¸ Augmented training to handle:
  - Scanned/camera images with rotation, color variance, warping.
- ğŸš« CNN model (Keras-based) was rejected due to:
  - ğŸ”¸ Low accuracy (<65%).
  - ğŸ”¸ Huge model size (~1GB).

### ğŸ“„ Document Extraction

- ğŸ”¥ Powered by **Qwen3-4B SLM** integrated with **DSPy** for composable LLM pipelines.
- âš¡ Reliable with <2% failure in extractions.
- ğŸ”— DSPy allows model-agnostic pipelines â€” easily switch between Qwen, Llama, Mixtral, GPT-4o.
- â³ Latency:
  - ~2 mins on MacBook M2.
  - 3â€“10 seconds on GPU (Google Colab or hosted GPUs).
- ğŸ§  Fallback with:
  - âœ… Regex-based pattern matching.
  - âœ… SpaCy-based NER (optional, usually not needed due to LLM accuracy).
- ğŸ’¡ Check `experiments/` folder for hybrid pipelines using Ollama + SpaCy.

### ğŸ” OCR Pipeline

- ğŸ–¼ï¸ Converts scanned images, or photos into machine-readable text.
- âš™ï¸ Use **PaddleOCR** for the process. mainly PP-OCRv5 for classifier and PP-Structuredv4 for extraction.
- ğŸš« Cons: heavy weight model pipeline required significant gpu power.

---

## ğŸ—ï¸ Approach & Architecture

### ğŸ”¥ End-to-End Pipeline

1. ğŸ“¥ Input (PDF/Image/Scanned)
2. ğŸ” **OCR** (PaddleOCR)
3. ğŸ—‚ï¸ **Classifier** â†’ Resume, Email, or Research Paper (custom finetuned BERT)
4. ğŸ“„ **Extractor** â†’ DSPy + Qwen3-4B (LLM extraction)
5. ğŸ©¹ **Fallback** â†’ Regex + SpaCy
6. ğŸš€ Output â†’ Structured JSON

___

| Component              | Accuracy / Reliability  | Latency (Mac M2) | Latency (GPU)  |
|----------------------- |------------------------ |------------------|----------------|
| Document Classifier    | ~94%                    | < 20s   (mpx)    | < 1s           |
| Qwen3-4B Extraction    | ~98% success            | ~2 min           | 3â€“10 seconds   |
| SpaCy + Regex Fallback | ~30â€“85% (task dependent)| < 10s            | < 10s          |

___

## ğŸ’¡ Design Decisions

| Component       | Choice                            | Reason                                                     |
|-----------------|-----------------------------------|------------------------------------------------------------|
| Classifier      | BERT-based Transformers           | Fast, lightweight, high accuracy.                          |
| CNN Model       | âœ… Tried, âŒ Rejected              | Large size & low accuracy.                                 |
| OCR             | PaddleOCR (PP-OCRv5 & PP-Structuredv4)       | Sufficient for standard scanned text.                      |
| Extraction      | DSPy + Qwen3:4B (Q4_K_M)                  | Model-agnostic, high reliability and performance.                          |
| Fallback        | Regex + SpaCy                     | Robust safety net in failure scenarios.                    |
| Deployment      | Streamlit + API      | Scalable, easy to integrate into larger systems.           |

___

## ğŸŒŸ Features

- ğŸ—‚ï¸ Document Classification: Resume, Email, Research Paper.
- ğŸ” Information Extraction:
  - **Resumes:** Name, Emails, Phones, Addresses, Websites, Social_profiles, Skills_categorized, Experience_insights, Achievement_metrics, Career_progression, Personality_traits
  - **Emails:** email_from, email_to, cc, bcc, subject, date, body, attachments, emotional_tone, intent_hierarchy, action_items, stakeholders, follow_up_required, priority_level, relationship_context
  - **Research Papers:**  title, authors, affiliations, abstract, keywords, sections, citations, references, figures_tables, doi, journal, publication_date, research_contribution, methodology_type, research_gaps_identified, future_work_suggestions

- ğŸ“„ Handles PDFs, scanned images, or camera photos.
- ğŸ’¥ LLM-based pipeline with fallback mechanisms.
- âš¡ FastAPI backend + streamlit frontent.
- ğŸ”§ Easily extendable to new document types.

___

## Submodules and setup instructions
### [OCR module](ocr/readme.md)
### [Streamlit Frontent](frontend/README.md)
### [MAIN API](api/README.md)
### [experiment notebooks](experiments/README.md)