{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c3278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visithkumarapperuma/Development/docu_classify/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/visithkumarapperuma/.cache/kagglehub/datasets/ritvik1909/document-classification-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ritvik1909/document-classification-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create 'data' directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Move all items from 'path' to 'data'\n",
    "for item in os.listdir(path):\n",
    "    src = os.path.join(path, item)\n",
    "    dst = os.path.join('data', item)\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6938519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd04128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tqdm.auto as tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import torch \n",
    "from datasets import Dataset, Features, Sequence, ClassLabel, Value, Array2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e210f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resume': 0, 'scientific_publication': 1, 'email': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in os.listdir(path)]\n",
    "idx2label = {v: k for v, k in enumerate(labels)}\n",
    "label2idx = {k: v for v, k in enumerate(labels)}\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c043a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 training examples, 15 validation examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "562b6661-857c-46bd-9dc6-8e2cda7c7285",
       "rows": [
        [
         "0",
         "data/resume/doc_000501.png",
         "resume"
        ],
        [
         "1",
         "data/resume/doc_000070.png",
         "resume"
        ],
        [
         "2",
         "data/resume/doc_000460.png",
         "resume"
        ],
        [
         "3",
         "data/resume/doc_000476.png",
         "resume"
        ],
        [
         "4",
         "data/resume/doc_000674.png",
         "resume"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/resume/doc_000501.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/resume/doc_000070.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/resume/doc_000460.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/resume/doc_000476.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/resume/doc_000674.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_path   label\n",
       "0  data/resume/doc_000501.png  resume\n",
       "1  data/resume/doc_000070.png  resume\n",
       "2  data/resume/doc_000460.png  resume\n",
       "3  data/resume/doc_000476.png  resume\n",
       "4  data/resume/doc_000674.png  resume"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(path):\n",
    "    images.extend([\n",
    "        f\"{path}/{label}/{img_name}\" for img_name in os.listdir(f\"{path}/{label}\")\n",
    "    ])\n",
    "    labels.extend([\n",
    "        label for _ in range(len(os.listdir(f\"{path}/{label}\")))\n",
    "    ])\n",
    "data = pd.DataFrame({'image_path': images, 'label': labels})\n",
    "\n",
    "train_data, valid_data = train_test_split(data, test_size=0.09, random_state=0, stratify=data.label)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "valid_data = valid_data.reset_index(drop=True)\n",
    "print(f\"{len(train_data)} training examples, {len(valid_data)} validation examples\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b68ce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visithkumarapperuma/Development/docu_classify/.venv/lib/python3.12/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in /Users/visithkumarapperuma/.paddlex/official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 2462.17it/s]\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in /Users/visithkumarapperuma/.paddlex/official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1050.28it/s]\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_textline_ori), the model files will be automatically downloaded and saved in /Users/visithkumarapperuma/.paddlex/official_models.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in /Users/visithkumarapperuma/.paddlex/official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 3663.15it/s]\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in /Users/visithkumarapperuma/.paddlex/official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1525.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    use_doc_orientation_classify=True, \n",
    "    use_doc_unwarping=True, \n",
    "    use_textline_orientation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ae5908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': 'data/resume/doc_000674.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([[[238,   0],\n",
      "        ...,\n",
      "        [238,   9]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[695, 958],\n",
      "        ...,\n",
      "        [695, 977]]], shape=(91, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([0, ..., 0], shape=(91,)), 'text_rec_score_thresh': 0.0, 'rec_texts': ['iveSiigator/iPrograifDifecior(Last，first，ffhGdie)：', 'BIOGRAPHICAL SKETCH', 'Giveelloiioiotekelncoultncollartecal', 'investigatorprogramdirectorPhotocopythispageforeachperson.', 'NAME', 'POSITION TITLE', 'VERMA,INDER M.', 'PROFESSOR', 'EDUCATiONBginwithbaccalaureaeorotherinitialprofesslonaleducationsuchasnursingandincludeposdoctoraltraining.)', 'YEAR', 'INSTITUTION AND LOCATION', 'DEGREE', 'CONFERRED', 'FIELD OF STUDY', 'Lucknow University, Lucknow India', 'M.Sc.', '1966', 'The Weizmann Institute, Rehovot, Israel', 'Biochemistry', 'Ph.D.', '1971', 'M.I.T.,Cambridge,MA', 'Biochemistry', 'Postdoc.', '1971-1974', 'Biology', 'RESEARCHANDPROFESSIONALEXPERIENCE:Concludingwithpresentpositionlisinchronologicalorderpreviousemploymentexperience,and', 'honors.Keyperonnlincludetherincialinvestigtorandanyotherinividualswoparticiateinthecientificdevelopmentorexecutionoftheprject.', 'Keypersonnltyicllyillicludellindividualswitdotoralorotherrofessionaldegreesbutisomeprjectswilincudeindividualsattemastrsr', 'baccalaureatelevelprovidedtheycontributeinasubstantivowaytothoscientificdevelopmentorexecutionoftheprojectncludepresentmembershipon', 'anyFederalGovermentpublicadviorycommitteeLisinchroologicalordertetitesilautorsandcompletereerencestoallpublicationsduingte', 'pastthreeyearsandtoreresenttiveerlierpublictiospertinenttotispplictionDTExEDwoGES.', 'RESEARCH ANDPROFESSIONALEXPERIENCE', '9/71', '3/74', 'Department of Biology, Massachusetts Institute of Technology', 'Cambridge,MA (with Dr. David Baltimore)', '4/74', '1/79', 'Assistant Professor, The Salk Institute, La Jolla, CA', '1/79', '1/83', 'Associate Professor, The Salk Institute, La Jolla, CA', '7/79', '1/83', 'Adjunct Associate Professor, Department of Biology, University of', 'California, San Diego, La Jolla, CA', '2/83', '1/85', 'Senior Member, Molecular Biology and Virology Laboratory, The', 'Salk Institute.La Jolla,CA', '7/83', 'Present', 'Adjunct Professor, Department of Biology, University of', 'California, La Jolla,CA', '2/85', 'Present', 'Professor, Molecular Biology and Virology Laboratory, The Salk', 'Institute, La Jolla, CA', 'ACADEMIC HONORS', '1967-1970', 'Reverend Solomon B. Caulker Memorial Fellowship', '1970-1973', 'Fellow,Jane CoffinChilds Memorial Fund for Medical Research', '1989-1992', 'Academic Council, The Salk Institute', '1990-Present', 'American Cancer Society Professor of Molecular Biology', '1991-1992', 'Chairman of the Faculty and Academic Council, The Salk Institute', 'MEMBERSHIPS', 'Virology Study Section 10/81·7/85: Ad hoc member and chairman of many site visit teams.', 'American Cancer Society Study Section 1986-1990: Chairman 1988-1990', 'Editor, Gene Expression', 'Editorial Boardof Virology. Mol.Endocrinol. J. Cell Biochem., Techniques,J. Virology', 'Overseas Advisor, Department of Biotechnclogy. Government of India 1983-Present', 'PUBLICATIONS (Dr. Verma has over 215 publications)', 'Inoue, J.,Kerr,L.D., Ransone,L.J., Bengal,E.,Hunter,T.,and Verma,I. M.(1991) c-RelaCtivates', 'but V-rel suppresses transcription from kB sites. Proc. Natl. Acad. Sci. USA 88:3715-3719.', 'Yen, J.. Wisdom, R. M.,Tratner.1.. and Verma, 1. M. (1991) An alternative spliced form of FosB is', 'a negative regulator of transcriptional activation and transformation by Fos proteins. Proc.', 'Natl. Acad,Sci.USA 88:5077-5081.', 'Scharfmann, R.,Axelrod,J.H., and Verma,I.M. (1991) Long term in vivo expression of retrovirus-', 'mediated gene transfer in mouse fibroblast implants. Proc. Natl. Acad. Sci. USA, 88:4626-', 'Krr.D.Iu.,nEu.AH.R.Jr r.', '4630.', 'The Rel-associated pp40protein prevents DNA bindingof Rel andNF-B:Relationship with IBβ', 'PHS398(Rev.9/91)', '(Form Page 6) Page', 'urrc', 'FF'], 'rec_scores': array([0.80416918, ..., 0.99181569], shape=(91,)), 'rec_polys': array([[[238,   0],\n",
      "        ...,\n",
      "        [238,   9]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[695, 958],\n",
      "        ...,\n",
      "        [695, 977]]], shape=(91, 4, 2), dtype=int16), 'rec_boxes': array([[238, ...,   9],\n",
      "       ...,\n",
      "       [695, ..., 977]], shape=(91, 4), dtype=int16)}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = ocr.predict(\"data/resume/doc_000674.png\")\n",
    "for res in result:\n",
    "    res.print()\n",
    "    res.save_to_img(\"output\")\n",
    "    res.save_to_json(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59ae9f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dabcdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_box(box, width, height):\n",
    "    return [\n",
    "        int(1000 * (box[0] / width)),\n",
    "        int(1000 * (box[1] / height)),\n",
    "        int(1000 * (box[2] / width)),\n",
    "        int(1000 * (box[3] / height)),\n",
    "    ]\n",
    "\n",
    "def get_box_from_quad(quad):\n",
    "    \"\"\"\n",
    "    Converts a 4-point quadrilateral into a rectangular bounding box.\n",
    "    Input: quad - list of 4 points: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]\n",
    "    Output: [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    x_coords = [point[0] for point in quad]\n",
    "    y_coords = [point[1] for point in quad]\n",
    "    return [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50f6ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ocr(example):\n",
    "    # Get the image\n",
    "    image = Image.open(example['image_path'])\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Run PaddleOCR\n",
    "    result = ocr.predict(example['image_path'])\n",
    "    \n",
    "    words = []\n",
    "    boxes = []\n",
    "\n",
    "    ocr_data = result[0]\n",
    "    \n",
    "    # Get texts and boxes from the OCR result\n",
    "    rec_texts = ocr_data['rec_texts']\n",
    "    rec_boxes = ocr_data['rec_boxes'] \n",
    "    \n",
    "    for i, text in enumerate(rec_texts):\n",
    "        if not text.strip():\n",
    "            continue\n",
    "            \n",
    "        box = rec_boxes[i]\n",
    "        \n",
    "        # Ensure box has 4 coordinates\n",
    "        if len(box) == 4:\n",
    "            box = [int(coord) for coord in box]\n",
    "            norm_box = normalize_box(box, width, height)\n",
    "            words.append(text)\n",
    "            boxes.append(norm_box)\n",
    "    \n",
    "    # Add to the example dict\n",
    "    example['words'] = words\n",
    "    example['bbox'] = boxes\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00bf6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3TokenizerFast, LayoutLMv3ForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "615561ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= LayoutLMv3TokenizerFast.from_pretrained(\"microsoft/layoutlmv3-base\", cache_dir=\"models/layoutlmv3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "23278aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
    "    words = [str(w).strip() for w in example['words'] if str(w).strip()]\n",
    "    boxes = example['bbox'][:len(words)]\n",
    "\n",
    "    # Ensure alignment of words and boxes\n",
    "    assert len(words) == len(boxes), \"Words and boxes must be aligned.\"\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        words,\n",
    "        boxes=boxes,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_seq_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Add label\n",
    "    encoding['labels'] = torch.tensor(label2idx[example['label']], dtype=torch.long)\n",
    "\n",
    "    return {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "\n",
    "# we need to define the features ourselves as the bbox of LayoutLM are an extra feature\n",
    "training_features = Features({\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'token_type_ids': Sequence(Value(dtype='int64')),\n",
    "    'label': ClassLabel(names=list(idx2label.keys())),\n",
    "    'image_path': Value(dtype='string'),\n",
    "    'words': Sequence(feature=Value(dtype='string')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca35459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataloader_from_df(data):\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "\n",
    "    # Apply OCR if needed\n",
    "    dataset = dataset.map(apply_ocr)\n",
    "\n",
    "    # Apply encoding\n",
    "    encoded_dataset = dataset.map(\n",
    "        encode_training_example,\n",
    "        remove_columns=dataset.column_names\n",
    "    )\n",
    "\n",
    "    encoded_dataset.set_format(\n",
    "        type='torch',\n",
    "        columns=['input_ids', 'attention_mask', 'bbox', 'labels']\n",
    "    )\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        encoded_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "10a9ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:56<00:00, 28.34s/ examples]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 36.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# train_dataloader = training_dataloader_from_df(train_data)\n",
    "valid_dataloader = training_dataloader_from_df(valid_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7965c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
